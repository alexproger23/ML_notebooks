{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "authorship_tag": "ABX9TyMbOUJrkHKEYD9o8pnI1Zgw"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 11826443,
     "sourceType": "datasetVersion",
     "datasetId": 7429271
    }
   ],
   "dockerImageVersionId": 31041,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# morphemic analysis"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "execution_count": 10,
   "source": "!pip install TorchCRF"
  },
  {
   "cell_type": "code",
   "source": "import pandas as pd\nimport torch",
   "metadata": {
    "_uuid": "fe1821d3-cb61-4e5a-aeb6-0073607c1287",
    "_cell_guid": "09b4dd26-52de-48ef-bc99-482071c4ab74",
    "trusted": true,
    "collapsed": false,
    "id": "-JYcFEEhbZoB",
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2025-05-16T10:22:35.340560Z",
     "iopub.execute_input": "2025-05-16T10:22:35.341186Z",
     "iopub.status.idle": "2025-05-16T10:22:37.239475Z",
     "shell.execute_reply.started": "2025-05-16T10:22:35.341163Z",
     "shell.execute_reply": "2025-05-16T10:22:37.238663Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-16T10:22:37.240607Z",
     "iopub.execute_input": "2025-05-16T10:22:37.240963Z",
     "iopub.status.idle": "2025-05-16T10:22:37.272462Z",
     "shell.execute_reply.started": "2025-05-16T10:22:37.240927Z",
     "shell.execute_reply": "2025-05-16T10:22:37.271644Z"
    }
   },
   "outputs": [
    {
     "execution_count": 2,
     "output_type": "execute_result",
     "data": {
      "text/plain": "'cuda'"
     },
     "metadata": {}
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": "dataframe = pd.read_csv(\"/kaggle/input/morpheme/morpheme_train.csv\", names=[\"word\", \"morph\"])\ndataframe.head()",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-16T10:22:38.604639Z",
     "iopub.execute_input": "2025-05-16T10:22:38.605369Z",
     "iopub.status.idle": "2025-05-16T10:22:38.703916Z",
     "shell.execute_reply.started": "2025-05-16T10:22:38.605343Z",
     "shell.execute_reply": "2025-05-16T10:22:38.703318Z"
    }
   },
   "outputs": [
    {
     "execution_count": 3,
     "output_type": "execute_result",
     "data": {
      "text/plain": "             word                                           morph\n0  обескровленный      о:PREF/бес:PREF/кровл:ROOT/енн:SUFF/ый:END\n1        подбелка                  под:PREF/бел:ROOT/к:SUFF/а:END\n2        якутянин                       якут:ROOT/ян:SUFF/ин:SUFF\n3    скомкиваться  с:PREF/ком:ROOT/к:PREF/ива:SUFF/ть:END/ся:POST\n4    приоткрыться        при:PREF/от:PREF/кры:ROOT/ть:END/ся:POST",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>morph</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>обескровленный</td>\n      <td>о:PREF/бес:PREF/кровл:ROOT/енн:SUFF/ый:END</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>подбелка</td>\n      <td>под:PREF/бел:ROOT/к:SUFF/а:END</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>якутянин</td>\n      <td>якут:ROOT/ян:SUFF/ин:SUFF</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>скомкиваться</td>\n      <td>с:PREF/ком:ROOT/к:PREF/ива:SUFF/ть:END/ся:POST</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>приоткрыться</td>\n      <td>при:PREF/от:PREF/кры:ROOT/ть:END/ся:POST</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": "targets = [\"ROOT\", \"PREF\", \"SUFF\", \"END\", \"POST\", \"LINK\", \"HYPH\", \"O\"]\nuniq_chars = set()\n\nfor word in dataframe['word']:\n    uniq = set([ch for ch in word])\n    uniq_chars = uniq_chars | uniq\n\nvocab_size = len(uniq_chars) + 1\nvocab_size",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-16T10:22:38.848316Z",
     "iopub.execute_input": "2025-05-16T10:22:38.848528Z",
     "iopub.status.idle": "2025-05-16T10:22:38.953889Z",
     "shell.execute_reply.started": "2025-05-16T10:22:38.848511Z",
     "shell.execute_reply": "2025-05-16T10:22:38.953179Z"
    }
   },
   "outputs": [
    {
     "execution_count": 4,
     "output_type": "execute_result",
     "data": {
      "text/plain": "34"
     },
     "metadata": {}
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": "target_tokenizer = {\"O\": 0} # padding\n\nfor i, targ in enumerate(targets[:-1]):\n    target_tokenizer[\"B-\" + targ] = i * 2 + 1\n    target_tokenizer[\"I-\" + targ] = i * 2 + 2",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-16T10:22:40.638621Z",
     "iopub.execute_input": "2025-05-16T10:22:40.639221Z",
     "iopub.status.idle": "2025-05-16T10:22:40.642850Z",
     "shell.execute_reply.started": "2025-05-16T10:22:40.639198Z",
     "shell.execute_reply": "2025-05-16T10:22:40.642207Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": "tokenizer = {token : i + 1 for i, token in enumerate(uniq_chars)} # 0 - padding",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-16T10:22:42.116508Z",
     "iopub.execute_input": "2025-05-16T10:22:42.117087Z",
     "iopub.status.idle": "2025-05-16T10:22:42.120569Z",
     "shell.execute_reply.started": "2025-05-16T10:22:42.117064Z",
     "shell.execute_reply": "2025-05-16T10:22:42.119718Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": "def split_morpheme(word):\n    parts = word.split('/')\n    splited = []\n    tags = []\n    for part in parts:\n        begin = 1\n        symbols, mask = part.split(':')\n        for char in symbols:\n            if begin:\n                tags.append(target_tokenizer[\"B-\" + mask])                \n                begin = 0\n            else:\n                tags.append(target_tokenizer[\"I-\" + mask])\n            if char == 'e':\n                char = 'е'\n            splited.append(tokenizer[char])\n    return splited, tags",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-16T10:22:43.491513Z",
     "iopub.execute_input": "2025-05-16T10:22:43.491783Z",
     "iopub.status.idle": "2025-05-16T10:22:43.496523Z",
     "shell.execute_reply.started": "2025-05-16T10:22:43.491762Z",
     "shell.execute_reply": "2025-05-16T10:22:43.495996Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": "split_morpheme(dataframe[\"morph\"][0])",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-16T10:22:45.073207Z",
     "iopub.execute_input": "2025-05-16T10:22:45.073479Z",
     "iopub.status.idle": "2025-05-16T10:22:45.078665Z",
     "shell.execute_reply.started": "2025-05-16T10:22:45.073460Z",
     "shell.execute_reply": "2025-05-16T10:22:45.078063Z"
    }
   },
   "outputs": [
    {
     "execution_count": 8,
     "output_type": "execute_result",
     "data": {
      "text/plain": "([4, 23, 10, 14, 19, 29, 4, 3, 27, 10, 33, 33, 16, 12],\n [3, 3, 4, 4, 1, 2, 2, 2, 2, 5, 6, 6, 7, 8])"
     },
     "metadata": {}
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": "import torch\nfrom torch import nn\nfrom TorchCRF import CRF\n\nclass MorphModel(nn.Module):\n    def __init__(self, vocab_size, target_size, layers=1, emb_size=50, hid_size=100):\n        super(MorphModel, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, emb_size)\n        self.biLSTM = nn.LSTM(emb_size, hid_size, num_layers=layers, bidirectional=True, batch_first=True)\n        self.hid2target = nn.Linear(hid_size * 2, target_size)\n        self.crf = CRF(target_size)\n\n    def forward(self, x, tags=None, mask=None):\n        emb = self.embedding(x)\n        lstm, _ = self.biLSTM(emb)\n        emiss = self.hid2target(lstm)\n\n        if tags != None:\n            loss = -self.crf(emiss, tags, mask=mask)\n            return loss\n        else:\n            morph = self.crf.viterbi_decode(emiss, mask=mask)\n            return morph\n\nmodel = MorphModel(vocab_size, len(target_tokenizer), layers=8).to(device)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-16T10:22:46.421430Z",
     "iopub.execute_input": "2025-05-16T10:22:46.421699Z",
     "iopub.status.idle": "2025-05-16T10:22:46.599403Z",
     "shell.execute_reply.started": "2025-05-16T10:22:46.421680Z",
     "shell.execute_reply": "2025-05-16T10:22:46.598838Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": "from torchinfo import summary\n\nsummary(model, (1, 5), dtypes=[torch.long])",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-15T21:12:16.923291Z",
     "iopub.execute_input": "2025-05-15T21:12:16.924711Z",
     "iopub.status.idle": "2025-05-15T21:12:16.939245Z",
     "shell.execute_reply.started": "2025-05-15T21:12:16.924665Z",
     "shell.execute_reply": "2025-05-15T21:12:16.937894Z"
    }
   },
   "outputs": [
    {
     "execution_count": 207,
     "output_type": "execute_result",
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nMorphModel                               --                        255\n├─Embedding: 1-1                         [1, 5, 50]                1,700\n├─LSTM: 1-2                              [1, 5, 200]               121,600\n├─Linear: 1-3                            [1, 5, 15]                3,015\n==========================================================================================\nTotal params: 126,570\nTrainable params: 126,570\nNon-trainable params: 0\nTotal mult-adds (Units.MEGABYTES): 0.61\n==========================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.01\nParams size (MB): 0.51\nEstimated Total Size (MB): 0.52\n=========================================================================================="
     },
     "metadata": {}
    }
   ],
   "execution_count": 207
  },
  {
   "cell_type": "code",
   "source": "from sklearn.model_selection import train_test_split\n\ntrain_dataframe, valid_dataframe = train_test_split(dataframe, test_size=0.2, shuffle=True)\nvalid_dataframe = valid_dataframe.reset_index(drop=True)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-16T10:22:53.276764Z",
     "iopub.execute_input": "2025-05-16T10:22:53.277139Z",
     "iopub.status.idle": "2025-05-16T10:22:53.821579Z",
     "shell.execute_reply.started": "2025-05-16T10:22:53.277117Z",
     "shell.execute_reply": "2025-05-16T10:22:53.821003Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": "from torch.utils.data import DataLoader, Dataset\nfrom torch.nn.utils.rnn import pad_sequence\n\n\nclass TrainDataset(Dataset):\n    def __init__(self, dataframe):\n        self.df = dataframe.reset_index(drop=True)\n        self.max_length = len(max(dataframe[\"word\"], key=lambda x: len(x)))\n        \n    def __getitem__(self, idx):\n        letters, tags = split_morpheme(self.df[\"morph\"][idx])\n        mask = [1 for i in range(len(letters))]\n\n        letters = torch.tensor(letters, dtype=torch.long)\n        tags = torch.tensor(tags, dtype=torch.long)\n        mask = torch.tensor(mask, dtype=torch.bool)\n        \n        return letters, tags, mask\n\n    def __len__(self):\n        return len(self.df)\n\ndef collate_fn(batch):\n    tokens, labels, masks = zip(*batch)\n    \n    tokens = pad_sequence(tokens, batch_first=True, padding_value=0)\n    labels = pad_sequence(labels, batch_first=True, padding_value=target_tokenizer[\"O\"])\n    masks = pad_sequence(masks, batch_first=True, padding_value=0)\n    return tokens, labels, masks\n\n\ntrain_dataset = TrainDataset(train_dataframe)\n\ndataloader = DataLoader(train_dataset, \n                        batch_size=16, \n                        collate_fn=collate_fn, \n                        shuffle=True, \n                        num_workers=4)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-16T10:22:53.822590Z",
     "iopub.execute_input": "2025-05-16T10:22:53.823033Z",
     "iopub.status.idle": "2025-05-16T10:22:53.838528Z",
     "shell.execute_reply.started": "2025-05-16T10:22:53.823005Z",
     "shell.execute_reply": "2025-05-16T10:22:53.837870Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": "from torch import optim\n\noptimizator = optim.Adam(model.parameters(), lr=0.001)\nepoch = 10\n\nfor ep in range(epoch):\n    sum_loss = 0\n    model.train()\n    for iteration, batch in enumerate(dataloader):\n        letters, tags, mask = batch\n        letters = letters.to(device)\n        tags = tags.to(device)\n        mask = mask.to(device)\n        loss = model(letters, tags, mask=mask).sum()\n        sum_loss += loss.item()/16\n        \n        if iteration % 100 == 0:\n            print(f\"iter {iteration}/{len(dataloader)}: {loss.item()/16}\")\n        \n        loss.backward()\n        optimizator.step()\n        optimizator.zero_grad()\n\n    model.eval()\n    valid_sum = 0\n    for i in range(len(valid_dataframe)):\n        letters, tags = split_morpheme(valid_dataframe[\"morph\"][i])\n        mask = torch.tensor([1 for i in range(len(letters))], dtype=torch.bool).to(device).unsqueeze(0)\n        letters = torch.tensor(letters, dtype=torch.long).to(device).unsqueeze(0)\n        tags = torch.tensor(tags, dtype=torch.long).to(device).unsqueeze(0)\n\n        valid_sum += model(letters, tags, mask).item()\n    print(f\"Epoch {ep}, Train: {sum_loss/len(dataloader)}, Validation: {valid_sum/len(valid_dataframe)}\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-16T10:22:55.892350Z",
     "iopub.execute_input": "2025-05-16T10:22:55.892923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "iter 0/2320: 23.922388076782227\niter 100/2320: 9.723794937133789\niter 200/2320: 6.5184783935546875\niter 300/2320: 6.271370887756348\niter 400/2320: 4.901465892791748\niter 500/2320: 5.170162677764893\niter 600/2320: 5.366547107696533\niter 700/2320: 3.5657942295074463\niter 800/2320: 5.006108283996582\niter 900/2320: 3.713489532470703\niter 1000/2320: 2.4658055305480957\niter 1100/2320: 3.010169744491577\niter 1200/2320: 2.7519514560699463\niter 1300/2320: 2.379098892211914\niter 1400/2320: 2.1198277473449707\niter 1500/2320: 2.5058813095092773\niter 1600/2320: 3.6669559478759766\niter 1700/2320: 2.3804259300231934\niter 1800/2320: 1.5029759407043457\niter 1900/2320: 2.728142261505127\niter 2000/2320: 2.3422579765319824\niter 2100/2320: 3.0906500816345215\niter 2200/2320: 1.9958736896514893\niter 2300/2320: 1.3129208087921143\nEpoch 0, Train: 3.812208751203685, Validation: 1.9997827324869304\niter 0/2320: 2.2191359996795654\niter 100/2320: 1.444195032119751\niter 200/2320: 1.0104520320892334\niter 300/2320: 2.0149881839752197\niter 400/2320: 2.1052865982055664\niter 500/2320: 0.4710690975189209\niter 600/2320: 1.4014182090759277\niter 700/2320: 1.429964303970337\niter 800/2320: 1.1494323015213013\niter 900/2320: 1.5627570152282715\niter 1000/2320: 0.819598913192749\niter 1100/2320: 1.9944819211959839\niter 1200/2320: 0.1717057228088379\niter 1300/2320: 1.2907111644744873\niter 1400/2320: 0.9817764759063721\niter 1500/2320: 1.3218679428100586\niter 1600/2320: 2.158895254135132\niter 1700/2320: 1.3345134258270264\niter 1800/2320: 0.8650435209274292\niter 1900/2320: 1.0771024227142334\niter 2000/2320: 1.4724555015563965\niter 2100/2320: 1.596079707145691\niter 2200/2320: 0.6694064140319824\niter 2300/2320: 1.2248551845550537\nEpoch 1, Train: 1.2297439372488137, Validation: 1.167461653032239\niter 0/2320: 1.1158370971679688\niter 100/2320: 1.237074851989746\niter 200/2320: 0.7040742635726929\niter 300/2320: 1.6111096143722534\niter 400/2320: 1.0842056274414062\niter 500/2320: 1.0445935726165771\niter 600/2320: 0.47281479835510254\niter 700/2320: 0.30821919441223145\niter 800/2320: 1.0595099925994873\niter 900/2320: 1.8371713161468506\niter 1000/2320: 0.49388647079467773\niter 1100/2320: 0.3509829044342041\niter 1200/2320: 0.6893219947814941\niter 1300/2320: 1.135418176651001\niter 1400/2320: 0.8504297733306885\niter 1500/2320: 0.6849524974822998\niter 1600/2320: 0.5295335054397583\niter 1700/2320: 0.7242211103439331\niter 1800/2320: 0.3468388319015503\niter 1900/2320: 0.42444634437561035\niter 2000/2320: 0.7790011167526245\niter 2100/2320: 0.35322558879852295\niter 2200/2320: 0.4420607089996338\niter 2300/2320: 0.5845991373062134\nEpoch 2, Train: 0.8610282991723768, Validation: 1.0013459148682455\niter 0/2320: 0.8629001379013062\niter 100/2320: 0.9707049131393433\niter 200/2320: 1.2466844320297241\niter 300/2320: 0.8119155168533325\niter 400/2320: 0.5371644496917725\niter 500/2320: 0.5850170850753784\niter 600/2320: 1.3008742332458496\niter 700/2320: 0.6275209188461304\niter 800/2320: 0.5667355060577393\niter 900/2320: 0.31995248794555664\niter 1000/2320: 1.141617774963379\niter 1100/2320: 0.16286802291870117\niter 1200/2320: 1.0078630447387695\niter 1300/2320: 0.8858335018157959\niter 1400/2320: 0.635826587677002\niter 1500/2320: 0.47758960723876953\niter 1600/2320: 0.6272444725036621\niter 1700/2320: 0.7936093807220459\niter 1800/2320: 0.5355223417282104\niter 1900/2320: 0.4288506507873535\niter 2000/2320: 0.36151230335235596\niter 2100/2320: 0.6511229276657104\niter 2200/2320: 0.9961446523666382\niter 2300/2320: 0.7073183059692383\nEpoch 3, Train: 0.6544533218032327, Validation: 0.8512685560003184\niter 0/2320: 0.6647026538848877\niter 100/2320: 0.33366692066192627\niter 200/2320: 0.677117109298706\niter 300/2320: 0.7040820121765137\niter 400/2320: 0.7066172361373901\niter 500/2320: 0.543393611907959\niter 600/2320: 0.840970516204834\niter 700/2320: 0.48988890647888184\niter 800/2320: 0.6634070873260498\niter 900/2320: 0.3719191551208496\niter 1000/2320: 0.6337416172027588\niter 1100/2320: 0.3548239469528198\niter 1200/2320: 0.5862131118774414\niter 1300/2320: 0.6877264976501465\niter 1400/2320: 0.6431649923324585\niter 1500/2320: 0.763209342956543\niter 1600/2320: 0.860607385635376\niter 1700/2320: 0.7337535619735718\niter 1800/2320: 0.4110323190689087\niter 1900/2320: 0.8386263847351074\niter 2000/2320: 0.8253333568572998\niter 2100/2320: 0.4725419282913208\niter 2200/2320: 0.15426325798034668\niter 2300/2320: 0.26762855052948\nEpoch 4, Train: 0.520697124918987, Validation: 0.768736771633718\niter 0/2320: 0.2865633964538574\niter 100/2320: 0.5267078876495361\niter 200/2320: 0.10916352272033691\niter 300/2320: 0.76606285572052\niter 400/2320: 0.10749375820159912\niter 500/2320: 0.3017406463623047\niter 600/2320: 0.5184019804000854\niter 700/2320: 1.1455692052841187\niter 800/2320: 0.8308029174804688\niter 900/2320: 0.23533105850219727\niter 1000/2320: 0.7853299379348755\niter 1100/2320: 0.5877671241760254\niter 1200/2320: 0.22852730751037598\niter 1300/2320: 0.6715795993804932\niter 1400/2320: 0.35288989543914795\niter 1500/2320: 0.7600893974304199\niter 1600/2320: 0.19921541213989258\niter 1700/2320: 0.06437933444976807\niter 1800/2320: 0.2996983528137207\niter 1900/2320: 0.23494648933410645\niter 2000/2320: 0.15871334075927734\niter 2100/2320: 0.38853681087493896\niter 2200/2320: 0.6537126302719116\niter 2300/2320: 1.0909720659255981\nEpoch 5, Train: 0.4183771716751929, Validation: 0.6984911569106884\niter 0/2320: 0.21494388580322266\niter 100/2320: 0.4080303907394409\niter 200/2320: 0.05473160743713379\niter 300/2320: 0.21333622932434082\niter 400/2320: 0.17993998527526855\niter 500/2320: 0.2739698886871338\niter 600/2320: 0.1914680004119873\niter 700/2320: 0.13862073421478271\niter 800/2320: 0.3242955207824707\niter 900/2320: 0.48639214038848877\niter 1000/2320: 0.11753416061401367\niter 1100/2320: 0.25190091133117676\niter 1200/2320: 0.4251549243927002\niter 1300/2320: 0.4985767602920532\niter 1400/2320: 0.37470412254333496\niter 1500/2320: 0.609133243560791\niter 1600/2320: 0.04286658763885498\niter 1700/2320: 0.33374249935150146\niter 1800/2320: 0.045132994651794434\niter 1900/2320: 0.3188880681991577\niter 2000/2320: 0.5256459712982178\niter 2100/2320: 0.31883037090301514\niter 2200/2320: 0.05807137489318848\niter 2300/2320: 0.13707232475280762\nEpoch 6, Train: 0.35640503206643565, Validation: 0.6902119646454762\niter 0/2320: 0.08106529712677002\niter 100/2320: 0.10071027278900146\niter 200/2320: 0.549363374710083\niter 300/2320: 0.2567927837371826\niter 400/2320: 0.1386622190475464\niter 500/2320: 0.4520292282104492\niter 600/2320: 0.0370258092880249\niter 700/2320: 0.10434877872467041\niter 800/2320: 0.11538755893707275\niter 900/2320: 0.21708786487579346\niter 1000/2320: 0.18599951267242432\niter 1100/2320: 0.5945124626159668\niter 1200/2320: 0.05647778511047363\niter 1300/2320: 0.6721737384796143\niter 1400/2320: 0.12384510040283203\niter 1500/2320: 0.27506691217422485\niter 1600/2320: 0.4206598997116089\niter 1700/2320: 0.27691566944122314\niter 1800/2320: 0.02821516990661621\niter 1900/2320: 0.25175654888153076\niter 2000/2320: 0.34981346130371094\niter 2100/2320: 0.20956027507781982\niter 2200/2320: 0.04747819900512695\niter 2300/2320: 0.18881595134735107\nEpoch 7, Train: 0.28005374474772093, Validation: 0.6744805186004006\niter 0/2320: 0.19797754287719727\niter 100/2320: 0.0900346040725708\niter 200/2320: 0.6255441904067993\niter 300/2320: 0.07973384857177734\niter 400/2320: 0.1384117603302002\niter 500/2320: 0.28684425354003906\niter 600/2320: 0.31697189807891846\niter 700/2320: 0.28531646728515625\niter 800/2320: 0.2550199031829834\niter 900/2320: 0.24251019954681396\niter 1000/2320: 0.4935213327407837\niter 1100/2320: 0.18056070804595947\niter 1200/2320: 0.7733595371246338\niter 1300/2320: 0.07657897472381592\niter 1400/2320: 0.05478489398956299\niter 1500/2320: 1.0101475715637207\niter 1600/2320: 0.5633077621459961\niter 1700/2320: 0.08414828777313232\niter 1800/2320: 0.22930490970611572\niter 1900/2320: 0.22373127937316895\niter 2000/2320: 0.17363369464874268\niter 2100/2320: 0.02913367748260498\niter 2200/2320: 0.1466960906982422\niter 2300/2320: 0.2010810375213623\nEpoch 8, Train: 0.2555415439965396, Validation: 0.6717128589585517\niter 0/2320: 0.1994941234588623\niter 100/2320: 0.06605017185211182\niter 200/2320: 0.3283883333206177\niter 300/2320: 0.3216681480407715\niter 400/2320: 0.0711202621459961\niter 500/2320: 0.26732778549194336\niter 600/2320: 0.06869077682495117\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "def concat(word, tags):\n    concated = ''\n    part = word[0]\n    last = tags[0]\n    for letter, tag in zip(word[1:], tags[1:]):\n        if tag[:2] == \"B-\":\n            concated += part + \":\" + last[2:] + '/'\n            part = ''\n        part += letter\n        last = tag\n    concated += part + \":\" + last[2:]\n        \n    return concated",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-16T10:56:43.124550Z",
     "iopub.execute_input": "2025-05-16T10:56:43.125086Z",
     "iopub.status.idle": "2025-05-16T10:56:43.129608Z",
     "shell.execute_reply.started": "2025-05-16T10:56:43.125066Z",
     "shell.execute_reply": "2025-05-16T10:56:43.128866Z"
    }
   },
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "source": "dataframe.head()",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-16T10:56:44.269620Z",
     "iopub.execute_input": "2025-05-16T10:56:44.270279Z",
     "iopub.status.idle": "2025-05-16T10:56:44.277676Z",
     "shell.execute_reply.started": "2025-05-16T10:56:44.270253Z",
     "shell.execute_reply": "2025-05-16T10:56:44.276785Z"
    }
   },
   "outputs": [
    {
     "execution_count": 25,
     "output_type": "execute_result",
     "data": {
      "text/plain": "             word                                           morph\n0  обескровленный      о:PREF/бес:PREF/кровл:ROOT/енн:SUFF/ый:END\n1        подбелка                  под:PREF/бел:ROOT/к:SUFF/а:END\n2        якутянин                       якут:ROOT/ян:SUFF/ин:SUFF\n3    скомкиваться  с:PREF/ком:ROOT/к:PREF/ива:SUFF/ть:END/ся:POST\n4    приоткрыться        при:PREF/от:PREF/кры:ROOT/ть:END/ся:POST",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>morph</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>обескровленный</td>\n      <td>о:PREF/бес:PREF/кровл:ROOT/енн:SUFF/ый:END</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>подбелка</td>\n      <td>под:PREF/бел:ROOT/к:SUFF/а:END</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>якутянин</td>\n      <td>якут:ROOT/ян:SUFF/ин:SUFF</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>скомкиваться</td>\n      <td>с:PREF/ком:ROOT/к:PREF/ива:SUFF/ть:END/ся:POST</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>приоткрыться</td>\n      <td>при:PREF/от:PREF/кры:ROOT/ть:END/ся:POST</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "source": "test_df = pd.read_csv(\"/kaggle/input/morpheme/morpheme_test.csv\", names=[\"word\"])",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-16T10:56:45.036599Z",
     "iopub.execute_input": "2025-05-16T10:56:45.037434Z",
     "iopub.status.idle": "2025-05-16T10:56:45.064970Z",
     "shell.execute_reply.started": "2025-05-16T10:56:45.037410Z",
     "shell.execute_reply": "2025-05-16T10:56:45.064366Z"
    }
   },
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "source": "reverse_target = {i : token for token, i in target_tokenizer.items()}\nreverse_target",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-16T10:56:45.280207Z",
     "iopub.execute_input": "2025-05-16T10:56:45.280517Z",
     "iopub.status.idle": "2025-05-16T10:56:45.285810Z",
     "shell.execute_reply.started": "2025-05-16T10:56:45.280498Z",
     "shell.execute_reply": "2025-05-16T10:56:45.285267Z"
    }
   },
   "outputs": [
    {
     "execution_count": 27,
     "output_type": "execute_result",
     "data": {
      "text/plain": "{0: 'O',\n 1: 'B-ROOT',\n 2: 'I-ROOT',\n 3: 'B-PREF',\n 4: 'I-PREF',\n 5: 'B-SUFF',\n 6: 'I-SUFF',\n 7: 'B-END',\n 8: 'I-END',\n 9: 'B-POST',\n 10: 'I-POST',\n 11: 'B-LINK',\n 12: 'I-LINK',\n 13: 'B-HYPH',\n 14: 'I-HYPH'}"
     },
     "metadata": {}
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "source": "words = []\nfor word in test_df[\"word\"]:\n    letters = [tokenizer[ch] for ch in word]\n    mask = torch.tensor([1 for i in range(len(letters))], dtype=torch.bool).to(device).unsqueeze(0)\n    letters = torch.tensor(letters, dtype=torch.long).to(device).unsqueeze(0)\n\n    ans = model(letters, mask=mask)\n    lst = []\n    for i in ans[0]:\n        lst.append(reverse_target[i])\n        \n    words.append(concat(word, lst))\n\ntest_df[\"morph\"] = words\ntest_df.head()",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-16T10:56:48.433137Z",
     "iopub.execute_input": "2025-05-16T10:56:48.433430Z",
     "iopub.status.idle": "2025-05-16T10:57:30.609592Z",
     "shell.execute_reply.started": "2025-05-16T10:56:48.433411Z",
     "shell.execute_reply": "2025-05-16T10:57:30.608847Z"
    }
   },
   "outputs": [
    {
     "execution_count": 28,
     "output_type": "execute_result",
     "data": {
      "text/plain": "             word                                 morph\n0  елизаветинский  елизавет:ROOT/ин:SUFF/ск:SUFF/ий:END\n1     кинофикация           кинофик:ROOT/аци:SUFF/я:END\n2          хиджра                      хиджр:ROOT/а:END\n3    магистерство          магистер:ROOT/ств:SUFF/о:END\n4   педантический         педантич:ROOT/еск:SUFF/ий:END",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>morph</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>елизаветинский</td>\n      <td>елизавет:ROOT/ин:SUFF/ск:SUFF/ий:END</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>кинофикация</td>\n      <td>кинофик:ROOT/аци:SUFF/я:END</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>хиджра</td>\n      <td>хиджр:ROOT/а:END</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>магистерство</td>\n      <td>магистер:ROOT/ств:SUFF/о:END</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>педантический</td>\n      <td>педантич:ROOT/еск:SUFF/ий:END</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "source": "model.eval()\nvalid_sum = 0\n\nfor i in range(len(valid_dataframe)):\n    letters, tags = split_morpheme(valid_dataframe[\"morph\"][i])\n    mask = torch.tensor([1 for i in range(len(letters))], dtype=torch.bool).to(device).unsqueeze(0)\n    letters = torch.tensor(letters, dtype=torch.long).to(device).unsqueeze(0)\n    tags = torch.tensor(tags, dtype=torch.long).to(device).unsqueeze(0)\n\n    model(letters, tags, mask).item()",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "test_df.to_csv(\"/kaggle/working/submission.csv\", index=False)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-16T11:13:04.875646Z",
     "iopub.execute_input": "2025-05-16T11:13:04.875946Z",
     "iopub.status.idle": "2025-05-16T11:13:04.910323Z",
     "shell.execute_reply.started": "2025-05-16T11:13:04.875926Z",
     "shell.execute_reply": "2025-05-16T11:13:04.909784Z"
    }
   },
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "source": "word = \"\"\nletters = [tokenizer[ch] for ch in word]\nmask = torch.tensor([1 for i in range(len(letters))], dtype=torch.bool).to(device).unsqueeze(0)\nletters = torch.tensor(letters, dtype=torch.long).to(device).unsqueeze(0)\n\nans = model(letters, mask=mask)\nlst = []\nfor i in ans[0]:\n    lst.append(reverse_target[i])\n    \nconcat(word, lst)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-16T11:30:49.376848Z",
     "iopub.execute_input": "2025-05-16T11:30:49.377608Z",
     "iopub.status.idle": "2025-05-16T11:30:49.387305Z",
     "shell.execute_reply.started": "2025-05-16T11:30:49.377584Z",
     "shell.execute_reply": "2025-05-16T11:30:49.386754Z"
    }
   },
   "outputs": [
    {
     "execution_count": 43,
     "output_type": "execute_result",
     "data": {
      "text/plain": "'литв:ROOT/ин:SUFF'"
     },
     "metadata": {}
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
